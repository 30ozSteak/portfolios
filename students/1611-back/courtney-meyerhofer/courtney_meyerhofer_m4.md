# Courtney Meyerhofer - M4 Portfolio

## Areas of Emphasis

For 4 module 

## Rubric Scores

Fill in how you would grade yourself from 1-4 in the following categories this module:

* **A: End-of-Module Assessment**: X
* **B: Individual Work & Projects**: 3
* **C: Group Work & Projects**: 3
* **D: Professional Skills**: 3
* **E: Feedback & Community Participation**: 4

-----------------------

## A: End of Module Assessment

(Notes & scores from your assessment rubric)


## B: Individual Work & Projects

#### Quantified Self

* [GitHub URL for API](https://github.com/meyerhoferc/quantified-self)
* [GitHub URL for Client](https://github.com/meyerhoferc/quantified-self-client)
* [GitHub URL for Production](https://meyerhoferc.github.io/quantified-self-client/)
* [Original Assignment](http://backend.turing.io/module4/projects/quantified-self/quantified-self)

Quantified Self is a full-stack JavaScript application with a Node.js/Express/Postgres API that connects to a static frontend using Javascript and jQuery for a calorie tracker. The application provides full CRUD functionality for foods and an API that also has endpoints for CRUD functionality with a food diary.

#### Specification Adherence

- 4: Application implements all functionality as defined, with no bugs, and one extension
- **3: Application implements all functionality as defined, but some bugs or strange behavior where features intersect**
- 2: Application is missing required functionality, deviates significantly from the spec, or serious bugs prevent features from being usable
- 1: Application is missing a significant portion of functionality

*Yay, adding food is using AJAX and not reloading the page!
I am allowed to enter in negative calories
I can't delete newly added foods unless I reload the page.*

#### Planning and Design

- 4: Team created visual schema, API documentation and user stories, before writing tests. API adheres to REST standard.
- **3: Team created either a schema or API docs to facilitate implementation of a service.**
- 2: Team has some notes on how to implement their service, but someone else couldn't implement it.
- 1: Team did not design their service.

*The API documentation is really good.  Did you have a schema for this project, just curious.*

#### Testing

- 4: All functionality is covered by tests. Appropriate mix of unit and integration tests. Sad path testing in both unit and integration tests.
- **3: All back-end functionality is covered by tests. Front-end uses unit tests wherever logic can be separated from interface and network requests.**
- 2: More back-end functionality implemented than tested and/or very little front-end testing
- 1: Team fails to effectively test the application.

3.5

*I appreciate you trying to write integration tests on the front end.  The syntax looks right and is clear.
I know we used a production site in the class example, but I think like you mentioned it makes more sense to
be testing against a development server.
The unit tests in the backend are well written and fast.*

#### HTML/UI

- 4: Team put some effort into styling. HTML features unique IDs, classes and data attributes for DOM traversal.
- **3: Application is not confusing to use. HTML classes and IDs are kebab case.**
- 2: HTML is greatly lacking in standards compliance. UI is confusing or very buggy.
- 1: Application is unusable

*Page looks great! Styled really well, UX is clean and nicely laid out.  Good use of grids.*

#### JS syntax and Style

- 4: Javascript features explicit DOM traversal (not using closest), demonstrates great OOP concepts, and uses named and anonymous functions when appropriate
- **3: Code logically divided into files. Developer can show examples of some SOLID concepts. Attention payed to indentation and naming.**
- 2: Javascript is noticeably lacking in the above concepts.
- 1: Team has not applied any style concepts from class or from Ruby background

3.5

*This doesn't really have to do with style and syntax but I like how you pass in the values to the models instead of the params object. Goood separation of concerns.  JS syntax and style follow convention.*


#### Git Workflow

- 4: Team uses master for production, and creates a feature branch for each card worked on. Team is using pull requests with good context and conversation
- **3: Team is using the feature branches for small groups of cards, and has a pull request for each feature. Developers that aren't on the team have commented on PRs.**
- 2: Team fails to use feature branches, or isn't using pull requests
- 1: All code is committed to master

*I'm going to give you a pass on git workflow since you were solo.*

#### Project Management

- 4: Team is using a project management tool and updating their progress daily. Team is approving each other's  work. Team is documenting conversations and conclusions on relevant cards.
- **3: Team is using a project management tool to keep their project organized.**
- 2: Team is using a project management tool but didn't update the progress frequently. Many cards have no changes made to them
- 1: Team failed to use a project management tool to track its progress.

## C: Group Work & Projects

### Projects

#### Capstone: Will Legislate For Money

* [GitHub URL](https://github.com/meyerhoferc/will-legislate-for-money)
* [Live Site](http://legislate.money)
* [Original Assignment](http://backend.turing.io/module4/capstone_project_overview)

Will Legislate For Money is a Python/Django app built as a tool to give voters easier access to information on their legislatorsâ€™ campaign funding and congressional action.

Main Takeaways: 

My main takeaways from this project was how to think through what features to implement and how to break apart that work given the current state of the application, the data that is available, and the amount of time we have for feature completion.

### 1. Project Management

*   **4: Tracker also documents feature related discussions**
*   3: Team is using well formatted user stories and moving cards through each status in realtime
*   2: Team has used Tracker as a respository of information
*   1: Tracker shows little to no use

### 2. Completion & Pace

*   **4: Team is proactive in understanding scope and is able to commit to stories before starting the sprint**
*   3: Team is able to set and update expectations so that there are no surprises on the last day of the sprint
*   2: Team does not have agreed upon stories completed at the end of the sprint, but has a plan to get them done
*   1: Team does not have agreed upon stories completed, and has no plan to complete them

### 3. Implementation Quality

*   4: Project demonstrates exceptionally well factored code.
*   **3: Project exhibits maintainable well divided code. Developers are able to speak to architecture and implementation decisions.**
*   2: Project demonstrates some gaps in code quality and/or developers cannot defend their decisions.
*   1: Project demonstrates poor factoring and/or understanding of MVC.

### 4. Application of Techniques

*   **4: Project has implemented two or more major techniques that were new this week.**
*   3: Project has implemented one major technique that was new this week.
*   2: Project has a implementation in progress of one major technique that has not been previously attempted.
*   1: Project does not implement new techniques.

### 5. Documentation

*   **4: Project also features a screencast, tutorial or other wow factor**
*   3: Project features easy to navigate documentation showing how to setup and contribute to the application
*   2: Project features barebones documentation showing how to get the dev environment up and running
*   1: Project has insufficient documentation

### 6. Accessibility

*   **4: Team has expertly implemented features to follow accessibility best practices.**
*   3: Team has implemented code to increase accessibility.
*   2: Team has considered accessibility issues but has not yet produced code to address them.
*   1: Team has not considered accessibility issues.



## D: Professional Skills

### Gear Up
#### Creating a Gear Up

* [Gear Up: Ethics and Technology of the Snowden Leaks](https://gist.github.com/blackknight75/c7ef4e8ef1a197d50593bce078fc9d7f)

Takeaways:

It was very fun to work with my peers to create a Gear Up for something we were interested in. We chose the ethics and technology of the Snowden leaks because it was something we were all passionate about discussing, and we had varying perspectives. We decided to present the information through videos and a reading and let most of the time be left up to discussion through case studies. It was very rewarding to hear people's perspectives, and I thought it was interesting that most people's overall opinions were uniform. It may be the case that we think we're discussing topics and providing people an outlet to explore something through gear ups, but most people ended up reinforcing their own opinions. I don't know if this is a feature or a bug of gear ups, but it was something I noticed.

### Open Source Contribution
#### WeTransfer: ImageVise service

* [Submitted PR](https://github.com/WeTransfer/image_vise/pull/9#discussion_r119997418)

### Playing a Part

I was co-lead of the Armstrong posse this inning with Max Glassie. This involved goal-setting and intentional planning as well as co-hosting events outside of normal Spike time. We hosted lunch on Tuesday every week, coordinated happy hours with alumni in the blockchain community, and prioritized passing along the leadership to keep the posse going after we leave. We created weekly agendas that involved giving lightning talks, working through tutorials, and hosting Q&As. 

I gave a talk at Denver.rb about the Ruby Interpreter and hosted/organized an interview prep session one weekend. I started a repo for Turing students to add interview questions related to general concepts, the cultural interview, and coding challenges. I also created a gear up session with Max Glassie, Dan Olson, and Ryan Spink about the ethics of the snowden leaks.

------------------

## Final Review

### Notes

( Leave blanks for reviewers )

### Outcome

( Leave blanks for reviewers )

